# awesome-automl   
collecting related resources of automated machine learning here. some links were from below:
- [hibayesian/awesome-automl-papers](https://github.com/hibayesian/awesome-automl-papers)   
- [literature-on-neural-architecture-search](http://www.ml4aad.org/literature-on-neural-architecture-search/)


---   
# Papers

## Architecture Search (and Hyperparameter Optimization):
- Kandasamy K, Neiswanger W, Schneider J, et al. [Neural Architecture Search with Bayesian Optimisation and Optimal Transport](https://arxiv.org/abs/1802.07191)[J]. arXiv preprint arXiv:1802.07191, 2018.
- Pham H, Guan M Y, Zoph B, et al. [Efficient Neural Architecture Search via Parameter Sharing](https://arxiv.org/abs/1802.03268)[J]. arXiv preprint arXiv:1802.03268, 2018.
- Kamath P, Singh A, Dutta D. [Neural Architecture Construction using EnvelopeNets](https://arxiv.org/abs/1803.06744)[J]. arXiv preprint arXiv:1803.06744, 2018.
- Real E, Aggarwal A, Huang Y, et al. [Regularized Evolution for Image Classifier Architecture Search](https://arxiv.org/abs/1802.01548)[J]. arXiv preprint arXiv:1802.01548, 2018.


Large-Scale Evolution of Image Classifiers (Real et al. 2017)
https://arxiv.org/abs/1703.01041
Hierarchical Representations for Efficient Architecture Search (Liu et al. 2017)
https://arxiv.org/abs/1711.00436
Neural Optimizer Search with Reinforcement Learning (Bello et al. 2017)
https://arxiv.org/abs/1709.07417
Progressive Neural Architecture Search (Liu et al. 2017)
https://arxiv.org/abs/1712.00559
Learning Transferable Architectures for Scalable Image Recognition (Zoph et al. 2017)
https://arxiv.org/abs/1707.07012
Simple And Efficient Architecture Search for Convolutional Neural Networks (Elsken et al. 2017) 
https://arxiv.org/abs/1711.04528
Finding Competitive Network Architectures Within a Day Using UCT (Wistuba 2017) 
https://arxiv.org/abs/1712.07420
Hyperparameter Optimization: A Spectral Approach (Hazan et al. 2017)
https://arxiv.org/abs/1706.00764
Population Based Training of Neural Networks (Jaderberg et al. 2017)
https://arxiv.org/abs/1711.09846
SMASH: One-Shot Model Architecture Search through HyperNetworks (Brock et al. 2017) 
https://arxiv.org/abs/1708.05344
Efficient Architecture Search by Network Transformation (Cai et al. 2017)
https://arxiv.org/abs/1707.04873
Towards Automatically-Tuned Neural Networks (Mendoza et al. 2016)
http://proceedings.mlr.press/v64/mendoza_towards_2016.html
Convolutional Neural Fabrics (Saxena and Verbeek 2016)
https://arxiv.org/abs/1606.02492
CMA-ES for Hyperparameter Optimization of Deep Neural Networks (Loshchilov and Hutter 2016)
https://arxiv.org/abs/1604.07269
Designing Neural Network Architectures using Reinforcement Learning (Baker et al. 2016) 
https://arxiv.org/abs/1611.02167
Neural Architecture Search with Reinforcement Learning (Zoph and Le. 2016)
https://arxiv.org/abs/1611.01578
Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization (Li et al. 2016) 
https://arxiv.org/abs/1603.06560
Optimizing deep learning hyper-parameters through an evolutionary algorithm (Young et al. 2015)
https://dl.acm.org/citation.cfm?id=2834896
Practical Bayesian Optimization of Machine Learning Algorithms (Snoek et al. 2012)
https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf  
Make it more efficient
Gitgraph â€“ From Computational Subgraphs to Smaller Architecture search spaces (Bennani-Smires et al. 2018)
https://openreview.net/pdf?id=rkiO1_1Pz
Transfer Automatic Machine Learning (Wong et al. 2018)
https://arxiv.org/abs/1803.02780
Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets (Klein et al. 2017)
http://proceedings.mlr.press/v54/klein17a.html
Learning curve prediction with Bayesian Neural Networks (Klein et al. 2017)
http://ml.informatik.uni-freiburg.de/papers/17-ICLR-LCNet.pdf
Multi-Objective NAS
PPP-Net: Platform-aware progressive search for pareto-optimal neural architectures (Dong et al. 2018)
https://openreview.net/pdf?id=B1NT3TAIM
